---
title:  "Time Series Predictions"
date: 2020-01-06
tags: [Time Series, Machine Learning, Data Science]
excerpt:  "Time Series Predictions"
---

A lot has been written about making predictions using time series data.  The general "go-to" when one sees a time series is to go right to ARIMA (Autoregressive Integrated Moving Average) models.  If ARIMA results are sub-par, standard practice is to move on to RNNs (Recurrent Neural Networks).  Yet is this a "good" approach?  

Arguably no.

The real answer - like most things in data science - is "it depends."

I have found that straight forward regressor modeling may return surprisingly good results.  In many cases it makes sense to try regression modelling alongside ARIMA/RNN modeling.

# ARIMA/RNN Models vs. Straightforward Regression models

ARIMA and RNN models are used when the user has a hypothesis that predicted time series values are based on past values of the series.  

ARIMA and RNNs make use of a series of data.  The theory behind these models is that the current value of a series is based on some number of past values.  ARIMA models assume an autocorrelated value (i.e., the present value in some way correlates with past values) and a relationship between the present value and the error terms of preceding values when the actual values are compared to an average value.  

<img src="{{site.url}}{{ site.baseurl }}/images/timeseries/ARIMA-formula.jpg" alt="">

Similarly, RNNs are predicated on the present value relying on current input values in addition to prior outputs.

<img src="{{site.url}}{{ site.baseurl }}/images/timeseries/RNN-formula.jpg" alt="">


Straightforward regression *does not* assume that past values impact the present value.   The assumption is only inputs from the *present time* predict the current outcome.  What impact the present inputs have is determined by training the model on inputs during prior periods.  
