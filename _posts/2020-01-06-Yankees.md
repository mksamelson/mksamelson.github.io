---
title:  "New York City Subway - Yankee Stadium Volume"
date: 2020-01-06
tags: [Time Series, Machine Learning, Data Science]
excerpt:  "New York City Subway - Yankee Stadium Volume"  
---

The general "go-to" for a time series problem is to go right to Autoregressive Integrated Moving Average (ARIMA) models.  Following ARIMA models, analysts versed in deep learning often move on to Recurrent Neural Networks (RNNs).  

Is this a "good" approach?  

Arguably no.

ARIMA and RNN models assume that previous values of the target variable have an influence on present and future values.  Many analysts assume this is the case. In fact, it may *not* be the case.

Target values in time series may have a strong relationship directly to features at prediction time.  Accordingly, if one has (or can meaningfully predict) feature values at future times, target values can be predicted through straightforward regression methods.

This is the case with New York City Subway exit values at the Yankee Stadium Station.  

The first analyst impulse is to treat this time series data using time series modelling.  However, as shown, volume has less to do with prior volumes and more to do with exogenous features.

# ARIMA, RNN, and 'Straightforward' Regression Models

ARIMA and RNN models are used when an analyst hypothesizes that future target values are influences, at least in part, by past values.  

The theory behind these models is that the current and future target values are influenced by past target values or prediction errors.  

ARIMA models assume an autocorrelation between the current target an prior target values (the 'AR' portion of the model) and the prediction errors on prior target values (the 'MA' of the model).  
<img src="{{site.url}}{{ site.baseurl }}/images/timeseries/ARIMA-formula.jpg" alt="">

Similarly, RNNs are predicated on the present value relying on current input values in addition to prior outputs.  In RNN neurons, previous outputs are combined with current period inputs before passing through an activation function to generate an output.

<img src="{{site.url}}{{ site.baseurl }}/images/timeseries/RNN-formula.jpg" alt="">

Straightforward regression *does not* assume that past targets impact the present value.   The assumption is only inputs from the *present time* predict the current outcome.  What impact the present inputs have is determined by training the model on inputs during prior periods.  A CART Regression Tree, the basis for a Random Forest Regressor, is shown below.

<img src="{{site.url}}{{ site.baseurl }}/images/timeseries/cart.png" alt="">

Note that model inputs *do not reflect* features from a prior time.  The model is trained using feature values that correspond to a particular output.  Predictions, when generated, involve running a set of features down the tree to determine the predicted output value.  

# The Data #

## Turnstile Data ##

New York City Subway turnstile data is available
[here](http://web.mta.info/developers/turnstile.html).

The website contains weekly data files with entry and exit volume by station/turnstile for every unit in the NYC Subway system in four hour increments.  The format is as follows:  

<img src="{{site.url}}{{ site.baseurl }}/images/timeseries/NYC-Subway-Time-Series-Data.jpg" alt="">

* CA / SCP / UNIT - Coded identifying features that identfy turnstile units at particular stations.  (New York City MTA provides keys in a file at the above link.)

* DATE - The date of station activity

* TIME - the four hour period during which activity took place (The figure above shows these periods at 22 minutes after hours 4, 8, 12, 16, and 00.  In fact, most stations/turnstiles are timestamped on the four hour increments.  This difference is dealt with in data preprocessing.)

* DESC - The type of data entry.  "REGULAR" for regular periodic reporting.  Another label for corrections.

* ENTRIES - The number of people entering through the turnstile.

* EXITS - The number of people exiting through the turnstile.

## Feature Engineering ##

Are there features other than ENTRIES that can help predict EXITS?  

ENTRIES has limited use.  If we chose to train a model with ENTRIES there is a problem.  We have ENTRIES values for past periods.  However, we don't have ENTRIES for a current or *future* period.  In order to make use of ENTRIES to help predict EXITS in future periods we would first need to *predict* ENTRIES and then use the prediction to help predict EXITS.  This is probably more trouble than it's worth.

We can generate some potentially helpful features from the DATE.  Using the Pandas Datetime function we can determine DAYOFWEEK.  `Datetime().dayofweek` applied to DATE will return an integer value of 0 through 6 beginning with Monday and ending with Sunday.
