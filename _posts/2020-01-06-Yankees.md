---
title:  "Time Series Predictions"
date: 2020-01-06
tags: [Time Series, Machine Learning, Data Science]
excerpt:  "Time Series Predictions"
---

A lot has been written about making predictions using time series data.  The general "go-to" when one sees a time series is to go right to ARIMA (Autoregressive Integrated Moving Average) models.  If ARIMA results are sub-par, standard practice is to move on to RNNs (Recurrent Neural Networks).  Yet is this a "good" approach?  

Arguably no.

The real answer - like most things in data science - is "it depends."

I have found that straight forward regressor modeling may return surprisingly good results.  In many cases it makes sense to try regression modelling alongside ARIMA/RNN modeling.

# ARIMA/RNN Models vs. Straightforward Regression models

ARIMA and RNN models are used when the user has a hypothesis that predicted time series values are based on past values of the series.  

ARIMA and RNNs make use of a series of data.  The theory behind these models is that the current value of a series is based on some number of past values.  ARIMA models assume an autocorrelated value (i.e., the present value in some way correlates with past values) and a relationship between the present value and the error terms of preceding values when the actual values are compared to an average value.  

<img src="{{site.url}}{{ site.baseurl }}/images/timeseries/ARIMA-formula.jpg" alt="">

Similarly, RNNs are predicated on the present value relying on current input values in addition to prior outputs.  In RNN neurons, previous outputs are combined with current period inputs before passing through an activation function to generate an output.

<img src="{{site.url}}{{ site.baseurl }}/images/timeseries/RNN-formula.jpg" alt="">

Straightforward regression *does not* assume that past values impact the present value.   The assumption is only inputs from the *present time* predict the current outcome.  What impact the present inputs have is determined by training the model on inputs during prior periods.  A CART Regression Tree, the basis for a Random Forest Regressor, is shown below.

<img src="{{site.url}}{{ site.baseurl }}/images/timeseries/cart.png" alt="">

Note that model inputs *do not reflect* features from a prior time.  The model is trained using feature values that correspond to a particular output.  Predictions, when generated, involve running a set of features down the tree to determine the predicted output value.  
