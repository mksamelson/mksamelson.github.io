---
title:  "Predicting Customer Churn"
date: 2019-11-20
tags: [Classification, Machine Learning, Data Science]
excerpt:  #"Predicting Customer Churn"
---

Customer retention is critical for all businesses.  Customers are the primary source of company revenue and
have a direct impact on the bottom line. Understanding engagement - and better yet being able to predict
engagement - can be particularly helpful to intercede in issues **before** they become problems.

In this post we examine three months of real pre-paid phone card data and develop a model to predict
customers who will drop the service in the fourth month.

All work is done in R.

## The Data

The data set consists of three months of pre-paid phone card data from June through August 2013.  There is also a
target variable indicating whether a customer dropped service in September 2013.

The initial data set consists of 65 features.  8 features are categorical and 57 features are continuous.

Historical, churn, and descriptive information is contained in a single excel file. One page contains various categorical and continuous factors on customer spending, phone use, SMS use, data use, and some other information. A second page contains a binary churn indicator showing which customers left in September 2013. A third page has definitions of variables.

A sample of features include:

  * user_number_outgoing_activity_in_days
  * user_spending
  * reloads_count
  * calls_outgoing_count

The initial data set also consists of 182343 observations.  This reflects client observations for each of three months. The number
of clients are approximately 65,000 in total.

Prior to any exploratory data analysis some data cleaning was necessary.  Monthly observations had to be split and customers not present
in all three months were removed.  To make full use of three months of features it was necessary to make three features for every one features:  labeling them feature_3, feature_2, and feature_1 to reflect the feature three, two, and one month prior to month of drop prediction.


## Exploratory Data Analysis (EDA)

EDA is skipped for purposes of this brief write up.  EDA is essential to understand the data set.  However, presentation of summary statistics, distributions, correlations, and other interpretations of data of approximately 180 features does not conveniently lend
itself to presentation in the context of a web page.  I looked at missingness, outliers, distributions, and feature correlations.  

Understanding that I would be applying low-bias boosted tree classifier and my objective was to get the best performing model possible, I did not perform any type of feature selection.  Furthermore, I did not perform any standardization or removal of correlated variables as
boosted tree models are generally insensitive to feature standardization and will pick relevant features in the context of model training.

It is certainly possible that standardizing continuous variables **may** slightly impact model performance or that near identical
performance could be achieved using only a subset of the data set.  However, these exercises are left for another time.

## Model

After munging and doing preliminary analysis of the historical data set, I chose to utilize a boosted tree model to predict churn. I utilized the xgbtree method in the Caret package which makes use of XgBoost. Boosted trees are exceptionally powerful and the XgBoost package is known to be particularly powerful. I used the Caret package to access XgBoost because I find data pre-processing, using cross validation in model training, and performing a grid search to obtain optimal model parameters to be easier to use in Caret than in XgBoost proper.

The best model had an AUC of approximately .92 and an error of approximately .11 using the accuracy metric.

To address the business problem (i.e., identify and contact customers who will leave in a subsequent month based) I found it best to use an ROC cutoff that balanced specificity and sensitivity and resulted in slightly lower accuracy but yielded a preferable mix of true positives and false positives beneficial to addressing the business problem.

Training the model is time and resource intensive. The model was trained in an AWS instance with 8G RAM and 30G memory. Run time in that environment was approximately one hour.

Since training the model may not be practical in terms of time and resources I have provided the analytics output as comments in the code file. Plots are in their own separate files in the repository. Unfortunately the trained model file was too large to upload to the Github repository.
